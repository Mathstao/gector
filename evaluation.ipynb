{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Iteration 1>\n",
      "Sentence Error Probability: 0.8968254327774048\n",
      "\n",
      "#### Before ####\n",
      "WHo is yourr daddy ?\n",
      "\n",
      "#### After #####\n",
      "WHo is yourr daddy ?\n",
      "\n",
      "[Model Correction]\n",
      "--------------------------------------------------------------------------------\n",
      "__START__                     $KEEP                         0.9907964468002319\n",
      "WHo                           $REPLACE_Who                  0.551882266998291\n",
      "is                            $KEEP                         0.9691675901412964\n",
      "yourr                         $REPLACE_you                  0.31872689723968506\n",
      "daddy                         $KEEP                         0.8281116485595703\n",
      "?                             $KEEP                         0.9950874447822571\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "host = \"http://0.0.0.0:8890/correct\"\n",
    "\n",
    "def call_gec(text):\n",
    "    data = {\n",
    "        \"text\": text,\n",
    "        'iterations': 3,\n",
    "        'min_probability': 0.7,\n",
    "        'min_error_probability': 0.5,\n",
    "        'add_spell_check': False,\n",
    "    }\n",
    "    resp = requests.post(host, json=data)\n",
    "    res = resp.json()\n",
    "    return res\n",
    "\n",
    "text = \"WHo is yourr daddy?\"\n",
    "res = call_gec(text)\n",
    "print(res['debug_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_m2_files = [\n",
    "#     '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/A.dev.gold.bea19.m2',\n",
    "#     '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/B.dev.gold.bea19.m2',\n",
    "#     '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/C.dev.gold.bea19.m2',\n",
    "#     '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/N.dev.gold.bea19.m2',\n",
    "#     '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/ABC.train.gold.bea19.m2',\n",
    "#     '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/ABCN.dev.gold.bea19.m2',\n",
    "    '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/ABCN.all.gold.bea19.m2'\n",
    "    \n",
    "]\n",
    "\n",
    "ref_m2 = []\n",
    "for rmf in ref_m2_files:\n",
    "    ref_m2.extend(open(rmf).read().split('\\n\\n'))\n",
    "\n",
    "orig_sents = [i.split('\\n')[0].lstrip('S ') for i in ref_m2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38693/38693 [1:01:21<00:00, 10.51it/s]\n"
     ]
    }
   ],
   "source": [
    "orig_file = './output/original.txt'\n",
    "\n",
    "cor_file = './output/wil_corrected_iter4_spell_check.txt'\n",
    "cor_m2_file = './output/wil_corrected_iter4_spell_check.m2'\n",
    "\n",
    "# cor_file = './output/wil_corrected_spell_check.txt'\n",
    "# cor_m2_file = './output/wil_corrected_spell_check.m2'\n",
    "\n",
    "of = open(orig_file, 'w')\n",
    "cf = open(cor_file, 'w')\n",
    "\n",
    "for sent in tqdm(orig_sents):\n",
    "    res = call_gec(sent, True)\n",
    "    of.write(sent+'\\n')\n",
    "    cf.write(res['data']+'\\n')\n",
    "    \n",
    "of.close()\n",
    "cf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/citao/anaconda2/envs/python37/bin/errant_parallel -orig ./output/original.txt -cor ./output/wil_corrected_iter4_spell_check.txt -out ./output/wil_corrected_iter4_spell_check.m2\n",
      "Loading resources...\n",
      "Processing parallel files...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "py_env_bin = '/home/citao/anaconda2/envs/python37/bin/'\n",
    "errant_parallel_bin = os.path.join(py_env_bin, 'errant_parallel')\n",
    "shell_cmd = \"{} -orig {} -cor {} -out {}\".format(errant_parallel_bin, orig_file, cor_file, cor_m2_file)\n",
    "print(shell_cmd)\n",
    "print(os.popen(shell_cmd).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================== Span-Based Correction ======================\n",
      "Category       TP       FP       FN       P        R        F0.5\n",
      "M              9018     5500     9095     0.6212   0.4979   0.5918\n",
      "R              18763    17999    25033    0.5104   0.4284   0.4916\n",
      "U              3725     3233     3861     0.5354   0.491    0.5259\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "31506\t26732\t37989\t0.541\t0.4534\t0.5209\n",
      "==============================================\n",
      "\n",
      "\n",
      "\n",
      "===================== Span-Based Correction ======================\n",
      "Category       TP       FP       FN       P        R        F0.5\n",
      "ADJ            244      625      838      0.2808   0.2255   0.2677\n",
      "ADJ:FORM       88       36       81       0.7097   0.5207   0.6617\n",
      "ADV            262      524      814      0.3333   0.2435   0.3104\n",
      "CONJ           49       52       319      0.4851   0.1332   0.3174\n",
      "CONTR          108      84       112      0.5625   0.4909   0.5466\n",
      "DET            4755     2210     3206     0.6827   0.5973   0.6637\n",
      "MORPH          611      1075     726      0.3624   0.457    0.378\n",
      "NOUN           519      1358     2585     0.2765   0.1672   0.2445\n",
      "NOUN:INFL      51       7        37       0.8793   0.5795   0.7969\n",
      "NOUN:NUM       1883     901      948      0.6764   0.6651   0.6741\n",
      "NOUN:POSS      235      109      211      0.6831   0.5269   0.6449\n",
      "ORTH           1729     2268     1662     0.4326   0.5099   0.4461\n",
      "OTHER          1458     3569     7649     0.29     0.1601   0.2495\n",
      "PART           347      171      250      0.6699   0.5812   0.6501\n",
      "PREP           3842     2315     3131     0.624    0.551    0.6079\n",
      "PRON           779      654      1077     0.5436   0.4197   0.5133\n",
      "PUNCT          6422     3475     5985     0.6489   0.5176   0.6176\n",
      "SPELL          1754     2942     1017     0.3735   0.633    0.4069\n",
      "VERB           1093     1076     3042     0.5039   0.2643   0.4266\n",
      "VERB:FORM      1613     1212     891      0.571    0.6442   0.5843\n",
      "VERB:INFL      16       6        16       0.7273   0.5      0.6667\n",
      "VERB:SVA       1210     423      358      0.741    0.7717   0.7469\n",
      "VERB:TENSE     2205     1490     2131     0.5968   0.5085   0.5767\n",
      "WO             233      150      903      0.6084   0.2051   0.4367\n",
      "\n",
      "=========== Span-Based Correction ============\n",
      "TP\tFP\tFN\tPrec\tRec\tF0.5\n",
      "31506\t26732\t37989\t0.541\t0.4534\t0.5209\n",
      "==============================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cor_file = './output/wil_corrected_iter5_spell_check.txt'\n",
    "cor_m2_file = './output/wil_corrected_iter5_spell_check.m2'\n",
    "ref_m2_file = '/home/citao/Edison_workspace/Edison_tmp_data/autocorrect/bea2019/wi+locness/m2/ABCN.all.gold.bea19.m2'\n",
    "\n",
    "errant_compare_bin = os.path.join(py_env_bin, 'errant_compare')\n",
    "shell_cmd = \"{} -hyp {} -ref {} -cat 1\".format(errant_compare_bin, cor_m2_file, ref_m2_file)\n",
    "print(os.popen(shell_cmd).read())\n",
    "\n",
    "shell_cmd = \"{} -hyp {} -ref {} -cat 2\".format(errant_compare_bin, cor_m2_file, ref_m2_file)\n",
    "print(os.popen(shell_cmd).read())\n",
    "\n",
    "# shell_cmd = \"{} -hyp {} -ref {} -cat 3 -dt\".format(errant_compare_bin, cor_m2_file, ref_m2_file)\n",
    "# print(os.popen(shell_cmd).read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If I had it to choose between both transportation I think I probably chose car because it is better for me to go by car then to go by bus . \n",
      "\n",
      "If I had to choose between both transportation I think I probably choose a car because it is better for me to go by car than to go by bus . \n",
      "\n",
      "[['it to', 'to', [9, 14]],\n",
      " ['chose', 'choose a', [69, 74]],\n",
      " ['then', 'than', [120, 124]]]\n",
      "\n",
      "In my opinion I think that public transport in future is going to continue to be used because there are a lot of people that does n't have enough money to pay for a car even if it is used , so public transport continue to have future but people are going to use more the cars then bus or underground . \n",
      "\n",
      "I think that public transport in the future is going to continue to be used because there are a lot of people that do n't have enough money to pay for a car even if it is used , so public transport will continue to have a future , but people are going to use more the cars then bus or underground . \n",
      "\n",
      "[['In my opinion I', 'I', [0, 15]],\n",
      " ['in', 'in the', [44, 46]],\n",
      " ['does', 'do', [125, 129]],\n",
      " ['transport', 'transport will', [200, 209]],\n",
      " ['have', 'have a', [222, 226]],\n",
      " ['future', 'future ,', [227, 233]]]\n",
      "\n",
      "But i was so mad at him and so ansiouns to make his life imposible , and soon my fear of death and my anger for all of the sufering i had been throug became stronger and bigger , i had made a desition i was goingo to do it , if he dedicated 4 years of his life tourtoring me and not wanting me to be happy i would the time is nesesary for him to have a miserable life and i wo nt stop until i had acomplished my goald \n",
      "\n",
      "But I was so mad at him and so ansiouns to make his life imposible , and soon my fear of death and my anger for all of the sufering i had been throug became stronger and greater , i had made a desition I was goingo to do it , if he dedicated 4 years of his life tourtoring me and not wanting me to be happy I would the time is necessary for him to have a miserable life and I wo n't stop until I have acomplished my goald \n",
      "\n",
      "[['i', 'I', [4, 5]],\n",
      " ['stronger and bigger', 'stronger and greater', [157, 176]],\n",
      " ['i', 'I', [201, 202]],\n",
      " ['i', 'I', [306, 307]],\n",
      " ['nesesary', 'necessary', [326, 334]],\n",
      " ['i', 'I', [372, 373]],\n",
      " ['nt', \"n't\", [377, 379]],\n",
      " ['i had', 'I have', [391, 396]]]\n",
      "\n",
      "econd reason . in the English syntaxis , the structure for construction paragraph or sentences , the verb is written before the subject , but no always , Which is the rule ? \n",
      "\n",
      "The second reason . In the English syntaxis , the structure for construction paragraph or sentences , the verb is written before the subject , but not always . What is the rule ? \n",
      "\n",
      "[['econd', 'The second', [0, 5]],\n",
      " ['in', 'In', [15, 17]],\n",
      " ['no', 'not', [142, 144]],\n",
      " [', Which', '. What', [152, 159]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrong_cases = [\n",
    "    \"If I had it to choose between both transportation I think I probably chose car because it is better for me to go by car then to go by bus .\",\n",
    "    \"In my opinion I think that public transport in future is going to continue to be used because there are a lot of people that does n't have enough money to pay for a car even if it is used , so public transport continue to have future but people are going to use more the cars then bus or underground .\",\n",
    "    \"But i was so mad at him and so ansiouns to make his life imposible , and soon my fear of death and my anger for all of the sufering i had been throug became stronger and bigger , i had made a desition i was goingo to do it , if he dedicated 4 years of his life tourtoring me and not wanting me to be happy i would the time is nesesary for him to have a miserable life and i wo nt stop until i had acomplished my goald\",\n",
    "    \"econd reason . in the English syntaxis , the structure for construction paragraph or sentences , the verb is written before the subject , but no always , Which is the rule ?\",\n",
    "]\n",
    "\n",
    "for c in wrong_cases:\n",
    "    res = call_gec(c)\n",
    "    print(c, '\\n')\n",
    "    print(res['data'], '\\n')\n",
    "    pprint(res['corrections'])\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': True,\n",
       " 'data': 'My name is Ci tao .',\n",
       " 'corrections': [['namme', 'name', [3, 8]], ['Citao', 'Ci tao', [12, 17]]],\n",
       " 'orig_tokens': [['My', 'namme', 'is', 'Citao', '.']],\n",
       " 'cor_tokens': [['My', 'name', 'is', 'Ci tao', '.']]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gec(\"My namme is Citao .\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': True,\n",
       " 'data': 'My name is Citao .',\n",
       " 'corrections': [['namme', 'name', [3, 8]]],\n",
       " 'orig_tokens': [['My', 'namme', 'is', 'Citao', '.']],\n",
       " 'cor_tokens': [['My', 'name', 'is', 'Citao', '.']]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gec(\"My namme is Citao .\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python37]",
   "language": "python",
   "name": "conda-env-python37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
